{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GloVe Wiki Gigaword 100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load gigaword-100 pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load GloVe\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.save('fstwk.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load(\"fstwk.d2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.get_vector(\"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_vector(\"apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-defined business topics and associated terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = pd.read_csv(\"TopicList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = topiclist.astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract word embeddings for each of the words in Related Words column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for j in range(0,len(topiclist.index)):\n",
    "    line = topiclist.at[j,'Related words'].replace(',','')\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    keywords = [word.lower() for word in line.split(' ')]\n",
    "    keywords = set([word for word in keywords if not word in stop_words]) \n",
    "    vw = []\n",
    "    for word in keywords:\n",
    "        try:\n",
    "            ## try to obtain the word vector of a given word. If it doesn't exist continue\n",
    "            vw.append(word_vectors.get_vector(word))\n",
    "        except:\n",
    "            continue\n",
    "    vw = np.array(vw, dtype=np.float)\n",
    "    topiclist = topiclist.astype(object)\n",
    "    topiclist.at[j,'TargetVector'] = np.sum(vw, axis=0, ).tolist()\n",
    "    if j == 81:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topiclist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Word Vector for a transcript call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_wordvector(keywords):\n",
    "    keywords = set(keywords)\n",
    "    vw = []\n",
    "    for word in keywords:\n",
    "        try:\n",
    "            ## try to obtain the word vector of a given word. If it doesn't exist continue\n",
    "            vw.append(word_vectors.get_vector(word))\n",
    "        except:\n",
    "            continue\n",
    "    vw = np.array(vw, dtype=np.float)\n",
    "    target_vector = np.sum(vw, axis=0, ).tolist()\n",
    "    return target_vector\n",
    "#     target_vector = np.sum(np.array([word_vectors.get_vector(w) for w in keywords]), axis=0).tolist()\n",
    "# target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the cosine similarity function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity( a, b ):  \n",
    "    a_norm = norm(a)\n",
    "    b_norm = norm(b)\n",
    "    if a_norm == 0.0 or b_norm == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(dot(a,b) / (a_norm * b_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcualte similarity score between the summer vectors of the predefined business terms and transcriptions calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score = 0 \n",
    "top_index = 0\n",
    "for row in range(0, len(df.index)):\n",
    "    target_vector = build_wordvector(df.at[row,'text'].split(' '))\n",
    "    for i in range(0, len(topiclist.index)):\n",
    "        if type(topiclist.at[i,'TargetVector']) is list:\n",
    "            score = similarity(topiclist.at[i,'TargetVector'], target_vector)\n",
    "            if score > top_score:\n",
    "                top_score = score\n",
    "                top_index = i\n",
    "            else:\n",
    "                continue\n",
    "    df.at[row,'TopicClassification'] = topiclist.at[top_index, 'Topic']\n",
    "    top_score = 0 \n",
    "    top_index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of calls: \" + str(len(df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Distribution bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['TopicClassification'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Distribution of Topics\", color='red')\n",
    "ax.set_xlabel(\"Topics\")\n",
    "ax.set_ylabel(\"Number of Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Distribution pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['TopicClassification'].value_counts().plot(kind='pie',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Distribution of Topics\", autopct='%1.1f%%')\n",
    "ax.set_xlabel(\"Topics\")\n",
    "ax.set_ylabel(\"Number of Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gigaword_glove_100_df = df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gigaword_glove_100_df.to_csv('gigaword_glove_100_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gensim Glove 6B 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = pd.read_csv(\"TopicList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "# download glove 300d from https://nlp.stanford.edu/projects/glove/\n",
    "filename = 'glove.6B.300d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wordvector(keywords):\n",
    "    keywords = set(keywords)\n",
    "    vw = []\n",
    "    for word in keywords:\n",
    "        try:\n",
    "            ## try to obtain the word vector of a given word. If it doesn't exist continue\n",
    "            vw.append(model.wv.word_vec(word))\n",
    "        except:\n",
    "            continue\n",
    "    vw = np.array(vw, dtype=np.float)\n",
    "    target_vector = np.sum(vw, axis=0, ).tolist()\n",
    "    return target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity( a, b ):  \n",
    "    a_norm = norm(a)\n",
    "    b_norm = norm(b)\n",
    "    if a_norm == 0.0 or b_norm == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(dot(a,b) / (a_norm * b_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = topiclist.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for j in range(0,len(topiclist.index)):\n",
    "    line = topiclist.at[j,'Related words'].replace(',','')\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    keywords = [word.lower() for word in line.split(' ')]\n",
    "    keywords = set([word for word in keywords if not word in stop_words]) \n",
    "    vw = []\n",
    "    for word in keywords:\n",
    "        try:\n",
    "            ## try to obtain the word vector of a given word. If it doesn't exist continue\n",
    "            vw.append(model.wv.word_vec(word))\n",
    "        except:\n",
    "            continue\n",
    "    vw = np.array(vw, dtype=np.float)\n",
    "    topiclist = topiclist.astype(object)\n",
    "    topiclist.at[j,'TargetVector'] = np.sum(vw, axis=0, ).tolist()\n",
    "    if j == 81:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score = 0 \n",
    "top_index = 0\n",
    "for row in range(0, len(df.index)):\n",
    "    target_vector = build_wordvector(df.at[row,'text'].split(' '))\n",
    "    for i in range(0, len(topiclist.index)):\n",
    "        if type(topiclist.at[i,'TargetVector']) is list:\n",
    "            score = similarity(topiclist.at[i,'TargetVector'], target_vector)\n",
    "            if score > top_score:\n",
    "                top_score = score\n",
    "                top_index = i\n",
    "            else:\n",
    "                continue\n",
    "    df.at[row,'TopicClassification'] = topiclist.at[top_index, 'Topic']\n",
    "    top_score = 0 \n",
    "    top_index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['TopicClassification'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Distribution of Topics\", color='red')\n",
    "ax.set_xlabel(\"Topics\")\n",
    "ax.set_ylabel(\"Number of Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['TopicClassification'].value_counts().plot(kind='pie',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Distribution of Topics\", autopct='%1.1f%%')\n",
    "ax.set_xlabel(\"Topics\")\n",
    "ax.set_ylabel(\"Number of Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_glove_300_df = df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_glove_300_df.to_csv('wiki_glove_300_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = pd.read_csv(\"TopicList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = topiclist.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### download the english fasttext word vectors from https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip\n",
    "#### for other languages visit: https://fasttext.cc/docs/en/pretrained-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = 'wiki.en.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.load_model(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model.get_word_vector(\"pay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model.get_nearest_neighbors(\"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wordvector(keywords):\n",
    "    keywords = set(keywords)\n",
    "    vw = []\n",
    "    for word in keywords:\n",
    "        try:\n",
    "            ## try to obtain the word vector of a given word. If it doesn't exist continue\n",
    "            vw.append(fasttext_model.get_word_vector(word))\n",
    "        except:\n",
    "            continue\n",
    "    vw = np.array(vw, dtype=np.float)\n",
    "    target_vector = np.sum(vw, axis=0, ).tolist()\n",
    "    return target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity( a, b ):  \n",
    "    a_norm = norm(a)\n",
    "    b_norm = norm(b)\n",
    "    if a_norm == 0.0 or b_norm == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(dot(a,b) / (a_norm * b_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist = topiclist.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for j in range(0,len(topiclist.index)):\n",
    "    line = topiclist.at[j,'Related words'].replace(',','')\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    keywords = [word.lower() for word in line.split(' ')]\n",
    "    keywords = set([word for word in keywords if not word in stop_words]) \n",
    "    vw = []\n",
    "    for word in keywords:\n",
    "        try:\n",
    "            ## try to obtain the word vector of a given word. If it doesn't exist continue\n",
    "            vw.append(fasttext_model.get_word_vector(word))\n",
    "        except:\n",
    "            continue\n",
    "    vw = np.array(vw, dtype=np.float)\n",
    "    topiclist = topiclist.astype(object)\n",
    "    topiclist.at[j,'TargetVector'] = np.sum(vw, axis=0, ).tolist()\n",
    "    if j == 81:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score = 0 \n",
    "top_index = 0\n",
    "for row in range(0, len(df.index)):\n",
    "    target_vector = build_wordvector(df.at[row,'text'].split(' '))\n",
    "    for i in range(0, len(topiclist.index)):\n",
    "        if type(topiclist.at[i,'TargetVector']) is list:\n",
    "            score = similarity(topiclist.at[i,'TargetVector'], target_vector)\n",
    "            if score > top_score:\n",
    "                top_score = score\n",
    "                top_index = i\n",
    "            else:\n",
    "                continue\n",
    "    df.at[row,'TopicClassification'] = topiclist.at[top_index, 'Topic']\n",
    "    top_score = 0 \n",
    "    top_index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiclist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['TopicClassification'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Distribution of Topics\", color='red')\n",
    "ax.set_xlabel(\"Topics\")\n",
    "ax.set_ylabel(\"Number of Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['TopicClassification'].value_counts().plot(kind='pie',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Distribution of Topics\", autopct='%1.1f%%')\n",
    "ax.set_xlabel(\"Topics\")\n",
    "ax.set_ylabel(\"Number of Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_df = df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_df.to_csv('fasttext_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit (conda)",
   "language": "python",
   "name": "python37464bitconda92af5ceb5c3446b4bef67bc2a88383b5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
